<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>StereoMFC</title>

    <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <!-- Required Core Stylesheet -->
    <link rel="stylesheet" href="node_modules/@glidejs/glide/dist/css/glide.core.min.css">
    <!-- Optional Theme Stylesheet -->
    <link rel="stylesheet" href="node_modules/@glidejs/glide/dist/css/glide.theme.min.css">


    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/image_slider.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        function compare() {
          var x, i;
          x = document.getElementsByClassName("img-comp-overlay");
          for (i = 0; i < x.length; i++) {
            compareImages(x[i]);
          }
          function compareImages(img) {
            var slider, img, clicked = 0, w, h;
            w = img.offsetWidth;
            h = img.offsetHeight;
            img.style.width = (w / 2) + "px";
        
            slider = document.createElement("DIV");
            slider.setAttribute("class", "img-comp-slider");
            img.parentElement.insertBefore(slider, img);
            slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
            slider.style.left = (w / 2) - (slider.offsetWidth / 2) + "px";
            
            slider.addEventListener("mousedown", slideReady);
            window.addEventListener("mouseup", slideFinish);
         
            function slideReady(e) {
              e.preventDefault();
              clicked = 1;
              window.addEventListener("mousemove", slideMove);
              window.addEventListener("touchmove", slideMove);
            }
            function slideFinish() {
              clicked = 0;
            }
            function slideMove(e) {
              var pos;
              if (clicked == 0) return false;
              pos = getCursorPos(e)
              if (pos < 0) pos = 0;
              if (pos > w) pos = w;
              slide(pos);
            }
            function getCursorPos(e) {
              var a, x = 0;
              e = (e.changedTouches) ? e.changedTouches[0] : e;
              a = img.getBoundingClientRect();
              x = e.pageX - a.left;
              x = x - window.pageXOffset;
              return x;
            }
            function slide(x) {
              img.style.width = x + "px";
              slider.style.left = img.offsetWidth - (slider.offsetWidth / 2) + "px";
            }
          }
        }
    </script>


</head>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="col-md-12 text-center" id="title">
                Incorporating dense depth into neural 3D representations for view synthesis and relighting <br>
                <small>
                    <!-- (In Submission to WACV 2024) -->
                </small>
            </h2>
        </div>
        <div class="row" id="author-row" style="margin:0 auto;">
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="author-table">
                   Anonymous authors.
                </table>
            </div>
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="uni-table">
                    <tr>
                        <td>
                            <!-- <a style="text-decoration:none" href="https://computationalimaging.rice.edu"> Computational Imaging Lab, Rice University </a> -->
                        </td>
                    </tr>
                </table>
            </div>
        </div>
    </div>
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script>

    
    <div class="container">
        <div class="row">
                <!-- <div class="col-md-3 col-md-offset-4 text-center"> -->
                    <div class="col-md-5 col-md-offset-3 ">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="./assets/sigasia_compressed-compressed.pdf">
                            <img src="./assets/small_images/pdf.png" height="50px">
                                <h4><strong>Paper[~4MB]</strong></h4>
                            </a>
                        </li>
                        <!-- <li> 
                            <a href="">
                                <img src="./assets/small_images/code_icon.png" height="50px"> 
                                <h4><strong>Code</strong></h4> 
                                <h5> Coming soon </h5> 
                            </a>
                        </li>  -->
                        <!-- <li>
                                <a href="">
                                <img src="./assets/small_images/data.png" height="50px"> 
                                <h4><strong>Data</strong></h4> 
                                <h5> Coming soon </h5> 
                                </a>
                        </li> -->

                    </ul>
                </div>
        </div>
    </div>

<p>     </p>
<p>     </p>

<p><small> </small></p>
<div class="row">
    <div class="col-md-5 col-md-offset-3">
        <h4 style="color:rgb(224, 86, 31);">
            <b>Content best viewed using Chrome, Safari or Edge.</b>. More updates coming soon.
        </h4>
    </div>
</div>

<p>     </p>
<p>     </p>
<div class="container">    

    <div class="row">
    <div class="col-md-12  ">
                <!-- <img src="./assets/MultiFlashStereoCamera-674S1-representative_image.jpg" alt="" class="img-responsive"> -->
                <img src="./assets/opening_figure.png" alt="" class="img-responsive">
                <!-- <img src="./img/workspace_schematic_NEW.png" alt="AltText" style="width: 771px;;height: 578px;"> -->
    </div>

   </div>
</div>
<p>     </p>
<p>     </p>

<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h2>
            StereoMFC (stereo multi-flash camera) prototype
        </h2>

        <!-- <iframe src="file_name.pdf" style="width: 100%;height: 100%;border: none;"></iframe>
         -->
        <p class="text-justify ">
            For our prototype, we use a pair of machine vision cameras (
                <a href="https://www.edmundoptics.com/p/gs3-u3-41c6c-c-1-grasshopper-usb-30-color-camera/30772/">FLIR Grashopper</a>
                ) with a 1'', 4MP CMOS imaging sensor of resolution of 2048 \(\times\) 2048 pixels. As we focus mainly on small scenes, we use two sets of lenses that yield a narrow field of view -- 12mm and 16mm fixed focal length lens (<a href="https://www.edmundoptics.com/p/12mm-c-series-fixed-focal-length-lens/14949/">Edmund Optics</a>). We use 80W 5600K white LEDs (<a href="https://www.digikey.com/en/products/detail/creeled-inc/CXA2540-0000-000N00W257F/4437055">CREE LED</a>) as flashes driven by a DC power supply and switched though MOSFETs controlled with a Arduino over USB. At each pose of our rig, we captured 12 images with each of the flash lights on (one light at a time) and one HDR image per camera. The cameras are configured to return a 12 bit Bayer image which is then de-Bayered to yield a 16 bit RGB image. We set the left and right cameras to be triggered simultaneously by an external synchronization signal. We configured the camera frame acquiring and the flash triggering programs to run on the same thread and synchronized the frame acquisition with the flashes through blocking function calls.
        </p>
    </div>
</div>

<div class="container">
    <div class="row">
    <div class="col-md-4  ">
        <img src="./assets/MFC_schematic.png" alt="AltText" style="width:640px;height:360px;">
    </div>
    <div class=" col-md-4 col-md-offset-3">
        <div class="sketchfab-embed-wrapper"> <iframe title="Assembly 1" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="480" height="480" src="https://sketchfab.com/models/42156b5886f64eb1a705a952c7f8d124/embed?ui_theme=dark"> </iframe> </div>
    </div>
    </div>
</div>

<!-- <p class="br30"></p> -->

<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h2>
            Demonstration of our pipeline
        </h2>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12  ">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="25%">
            <h4>RGB and depth (Left)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>RGB and depth (Right)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Normals and edges (Left)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Normals and edges (Right)</h4>
        </td>
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome1" loop playsinline autoPlay muted src="assets/movies/rgb_depth_left.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome1Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome2" loop playsinline autoPlay muted src="assets/movies/rgb_depth_right.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome2Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome3" loop playsinline autoPlay muted src="assets/movies/normals_and_depth_edges_left.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome3Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome4" loop playsinline autoPlay muted src="assets/movies/normals_and_depth_edges_right.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome4Merge"></canvas>
            </div>
        </td>
    </tr>
</table>

</div>
</div>
</div>


<div class="container">
    <div class="row">
        <div class="col-md-12">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="33%">
            <h4>Mesh with diffuse texture</h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4>Left and right flash images</h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4>Mesh with truncated BRDF texture</h4>
        </td>
        <!-- <td align="center" valign="center" width="25%">
            <h4>Normals and edges (Right)</h4>
        </td> -->
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <div class="sketchfab-embed-wrapper"> <iframe title="mesh_diffuse" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="370" height="370" src="https://sketchfab.com/models/3480cdacdb52471da287a8c2645b3833/embed"> </iframe> 
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:96%">
                <video class="video" id="gnome5" loop playsinline autoPlay muted src="assets/movies/left_right_multilight.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome5Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="sketchfab-embed-wrapper"> <iframe title="lego_plant_wildlight_smaller_param_set" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="370" height="370" src="https://sketchfab.com/models/2a678525442d4077a3a16bad6002070f/embed"> </iframe> </div>
        </td>
    </tr>
</table>
</div>
</div>
</div>

<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h3>
            Capturing and relighting a human face
        </h3>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12  ">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="25%">
            <h4>Capture sequence (1 of 2)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Geometry</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Surface Relighting </h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Volumetric Relighting</h4>
        </td>
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <video width="290" height="290" controls>
                <source src="assets/movies/face_wig2_capture_no_sound.mp4" type="video/mp4">
              </video>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="sketchfab-embed-wrapper"> <iframe title="mesh" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="290" height="290" src="https://sketchfab.com/models/7bde2d0459204b37b9482f00ff8b78c9/embed"> </iframe> </div>
        </td>
        <td align="center" valign="center" width="100%">
            <video width="290" height="290" controls>
                <source src="assets/movies/face_surf_relit.mp4" type="video/mp4">
              </video>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:115%">
                <video class="video" id="gnome26" loop playsinline autoPlay muted src="assets/movies/face_wig_volrend.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome26Merge"></canvas>
            </div>
        </td>
    </tr>
</table>

</div>
</div>
</div>



<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <p class="text-justify ">
            Our system captures the scene using a stereoMFC and yields color images (left and right channels), aligned depth maps (left and right),  normals and depth edges. We use this to model the scene's radiance and geometry. After the scene's diffuse color has been captured, we use the multi-flash images and a truncated set of the Disney BRDF parameters to model the illumination dependent aspects of the scene. 
        </p>
        <img src="./assets/training_schedule.png" alt="" class="img-responsive">
    </div>
</div>


<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h2>
            Similarities with AdaptiveShells [Wang et al. SIGGRAPH Asia 2023]
        </h2>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-15">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="40%">
            <h4> GT(left) vs Reconstruction(right)</h4>
        </td>
        <td align="center" valign="center" width="20%">
            <h4>Crops</h4>
        </td>
        <td align="center" valign="center" width="40%">
            <h4>Shells (sampling volumes)</h4>
        </td>

    </tr>
    <tr>
        <td align="center" valign="center" width="40%">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/diffuse_scene_recon.png" width="370" height="370">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/diffuse_scene_GT.png" width="370" height="370">
                </div>
        </div>
        </td>
        <td align="right" valign="center" width="20%">
            <img src="./assets/diffuse_scene_crop.png" width="163" height="370">
        </td>
        <td align="center" valign="center" width="40%">
            <div class="sketchfab-embed-wrapper"> <iframe title="adashell_diffuse_scene" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="370" height="370" src="https://sketchfab.com/models/b1acb750e831484cb18c17d8c9b0a33e/embed"> </iframe> </div>
        </td>
    </tr>
    <!-- ----------------------------------- -->
    <tr>
        <td align="center" valign="center" width="40%">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/ponies_recon.png" width="370" height="370">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/ponies_gt.png" width="370" height="370">
                </div>
        </div>
        </td>
        <td align="right" valign="center" width="20%">
            <img src="./assets/ponies_crop.png" width="163" height="370">
        </td>
        <td align="center" valign="center" width="40%">
            <div class="sketchfab-embed-wrapper"> <iframe title="adashell_ponies" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="370" height="370" src="https://sketchfab.com/models/2e0a0b4319a6484e94281e2f138a776a/embed"> </iframe> </div>
        </td>
    </tr>
</table>
</div>
</div>
</div>

<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h3>
            Processing geometry with thin details
        </h3>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12  ">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="25%">
            <h4>RGB & depth (Left, geometry 1)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Normals & edges (Left, geometry 1)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>RGB & depth (Right, geometry 2)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Normals & edges (Right, geometry 2)</h4>
        </td>
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome10" loop playsinline autoPlay muted src="assets/movies/left_straight_wig_rgb_depth.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome10Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome11" loop playsinline autoPlay muted src="assets/movies/left_straight_wig_normal_edges.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome11Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome12" loop playsinline autoPlay muted src="assets/movies/right_curly_wig_rgb_depth.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome12Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome13" loop playsinline autoPlay muted src="assets/movies/right_curly_wig_normal_edges.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome13Merge"></canvas>
            </div>
        </td>
    </tr>
</table>

</div>
</div>
</div>

<p>     </p>
<p>     </p>
<p>     </p>
<p>     </p>

<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <p class="text-justify">
            Although a voumetric representation is more photorealistic for capturing thin geometries, we present a mesh based representation and the shells extracted by our method. The examples below have been trained with 4 stereo pairs: 7 images to train, 1 to test, total train time ~55 mins, 35K gradient steps, test PSNR: 29+. However, as we bake the appearance as diffuse texture, our psnr drops to about 25 across both cases. 
        </p>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-15">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="25%">
            <h4>Geometry 1 : Textured mesh</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Geometry 1 : Shell</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Geometry 2 : Textured mesh</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Geometry 2 : Shell</h4>
        </td>
    </tr>
    <tr>
        <td align="center" valign="center" width="25%">
            <div class="sketchfab-embed-wrapper"> <iframe title="adashell_ponies" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="false" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="290" height="290" src="https://sketchfab.com/models/39f7ba68d25e45e6adfade8af035305f/embed"> </iframe> </div>
        </td>
        <td align="center" valign="center" width="25%">
            <div class="sketchfab-embed-wrapper"> <iframe title="adashell_ponies" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="false" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="290" height="290" src="https://sketchfab.com/models/e28d5eacf97f4894aa2f5f0f2deb1dfa/embed"> </iframe> </div>
        </td>
        <td align="center" valign="center" width="25%">
            <div class="sketchfab-embed-wrapper"> <iframe title="adashell_ponies" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="false" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="290" height="290" src="https://sketchfab.com/models/eabf2577752e42c9831699eeb4977479/embed"> </iframe> </div>
        </td>
        <td align="center" valign="center" width="25%">
            <div class="sketchfab-embed-wrapper"> <iframe title="adashell_ponies" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="false" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="290" height="290" src="https://sketchfab.com/models/9cf25a24a3844016848883ce3278c202/embed"> </iframe> </div>
        </td>
    </tr>
</table>

</div>
</div>
</div>

<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h3>
            Quality of reconstruction with a volumetric renderer
        </h3>
        <h5>
            The views are rendered at 256x256 pixels, for a higher resolution image, please check out our paper draft! The training was stopped at a test PSNR of 27.5+ or 100K gradient steps (whichever was earlier).
        </h5>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="25%">
            <h4>VolSDF\(^{†}\)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>NeUS\(^{†}\)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>AdaShell\(^{†}\)</h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>UniSurf\(^{†}\)</h4>
        </td>
    </tr>
</table>
</div>
</div>
</div>

<div class="container">
    <div class="row">
    <div class=" col-md-3 ">
            <div class="img-comp-container">
                    <div class="img-comp-img">
                      <img src="./assets/lego_plant_gt.png" width="256" height="256">
                    </div>
                    <div class="img-comp-img img-comp-overlay">
                      <img src="./assets/lego_plant_volsdf.png" width="256" height="256">
                    </div>

            </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/lego_plant_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/lego_plant_neus.png" width="256" height="256">
                </div>

        </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/lego_plant_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/lego_plant_adashell.png" width="256" height="256">
                </div>

        </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/lego_plant_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/lego_plant_unisurf.png" width="256" height="256">
                </div>

        </div>
        </div>
    </div>
</div>

<p class="br20"></p>

<div class="container">
    <div class="row">
    <div class=" col-md-3 ">
            <div class="img-comp-container">
                    <div class="img-comp-img">
                      <img src="./assets/aluminum_star_gt.png" width="256" height="256">
                    </div>
                    <div class="img-comp-img img-comp-overlay">
                      <img src="./assets/aluminum_star_volsdf.png" width="256" height="256">
                    </div>

            </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/aluminum_star_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/aluminum_star_neus.png" width="256" height="256">
                </div>

        </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/aluminum_star_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/aluminum_star_adashell.png" width="256" height="256">
                </div>

        </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/aluminum_star_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/aluminum_star_unisurf.png" width="256" height="256">
                </div>

        </div>
        </div>
    </div>
</div>

<p class="br20"></p>

<div class="container">
    <div class="row">
    <div class=" col-md-3 ">
            <div class="img-comp-container">
                    <div class="img-comp-img">
                      <img src="./assets/reflective_gt.png" width="256" height="256">
                    </div>
                    <div class="img-comp-img img-comp-overlay">
                      <img src="./assets/reflective_volsdf.png" width="256" height="256">
                    </div>

            </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/reflective_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/reflective_neus.png" width="256" height="256">
                </div>

        </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/reflective_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/reflective_adashell.png" width="256" height="256">
                </div>

        </div>
        </div>
        <div class=" col-md-3 ">
            <div class="img-comp-container">
                <div class="img-comp-img">
                  <img src="./assets/reflective_gt.png" width="256" height="256">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/reflective_unisurf.png" width="256" height="256">
                </div>

        </div>
        </div>
    </div>
</div>

<p class="br20"></p>

<!-- ----------------------------------- -->
<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h3>
            Reconstructing a very shiny object
        </h3>
        <h5>
            <p class="text-justify ">            
            The reconstruction is created with 7 RGBD images from 4 stereo pairs (one RGBD reserved for validation). Time taken to refine geometry and base color: ~40 mins (100K grad steps). Time to recover partial BRDF model (~4 hrs). We recovered specularity, roughness and \(r_0\), the Fresnel reflection component. The web based display tool used here ignores \(r_0\). 
        </p>
        </h5>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="33%">
            <h4>Captured RGB and Depth </h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4>Multi-flash (12 x 4 x 2) (Left & Right)</h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4>Mesh with truncated BRDF texture</h4>
        </td>
        <!-- <td align="center" valign="center" width="25%">
            <h4>Normals and edges (Right)</h4>
        </td> -->
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:92%">
                <video class="video" id="gnome14" loop playsinline autoPlay muted src="assets/movies/aluminum_star_rgb_normals.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome14Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:96%">
                <video class="video" id="gnome15" loop playsinline autoPlay muted src="assets/movies/aluminum_star_multi_light.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome15Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="sketchfab-embed-wrapper"> <iframe title="lego_plant_wildlight_smaller_param_set" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="370" height="360" src="https://sketchfab.com/models/fd4bfba668044c5fa1451eb7bda434d8/embed"> </iframe> </div>
        </td>
    </tr>
</table>
</div>
</div>
</div>

<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h3>
            Relighting faces 
        </h3>
        <h5>
            <p class="text-justify ">
            The reconstruction is created with 2 stereo pairs -- 3 RGBD images to train, 1 to test. Time taken to refine geometry and base color: ~20 mins (100K grad steps). Time to recover partial BRDF model (~4 hrs). We recovered specularity, roughness and \(r_0\), the Fresnel reflection component. The movie is rendered approximately from the view of a camera placed between the stereo cameras. We use Blenders keyframing tool to manually choose 20 locations of the light 10 on the plane of the camera and 10 around the object and render 200 relit images using Blender. Blender does not support our exact reflectace model so like before, we drop \(r_0\), the Fresnel reflection component. We use Blender's Cycles renderer with an SPP of 2048 @ 1536x1536 pixels and rescale it to 370 x 370 pixels below. 
        </p>
        </h5>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="33%">
            <h4>Multi-flash pair (12 x 2) (L & R) </h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4>Normals and edges (or specularities) (L & R)</h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4>200 new light positions @ 1FPS</h4>
        </td>
        <!-- <td align="center" valign="center" width="25%">
            <h4>Normals and edges (Right)</h4>
        </td> -->
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome16" loop playsinline autoPlay muted src="assets/movies/sarv_multi_light.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome16Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:96%">
                <video class="video" id="gnome17" loop playsinline autoPlay muted src="assets/movies/sarv_depth_edges_normals_slow.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome17Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <video width="370" height="370" controls>
                <source src="assets/movies/sarv_relit_synth.mp4" type="video/mp4">
              </video>
        </td>
    </tr>

    <!-- <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome18" loop playsinline autoPlay muted src="assets/movies/chrisrelight_stereo.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome18Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:96%">
                <video class="video" id="gnome19" loop playsinline autoPlay muted src="assets/movies/chris_depth_normals_slow.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome19Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <video width="370" height="370" controls>
                <source src="assets/movies/chris_relight_synth.mp4" type="video/mp4">
              </video>
        </td>
    </tr> -->


    <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome20" loop playsinline autoPlay muted src="assets/movies/al_plate_mfc.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome20Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:92%">
                <video class="video" id="gnome21" loop playsinline autoPlay muted src="assets/movies/al_plate_spec_normals_slow.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome21Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <video width="370" height="370" controls>
                <source src="assets/movies/self_al_plate_relight_sym.mp4" type="video/mp4">
              </video>
        </td>
    </tr>

</table>
</div>
</div>
</div>

<!-- <div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h3>
            Accuracy of reconstructing synthetic scenes. 
        </h3>
        <p class="text-justify ">
  
            For <em><b>un-posed</b></em> RGBD images, we compare the accuracy of reconstructing the scene using VolSDF\(^{\dagger}\) and NeUS\(^{\dagger}\) with NeuralRGBD[Azinovic et al. 2022] and BundleFusion[Daiet al. 2017]. We report normalized chamfer distances (<u>lower is better</u>) across four synthetic scenes from BlendSwap.com. We use the pipeline described in section 4.1 to estimate the camera poses. For <em><b>posed</b></em> synthetic RGBD sequences, we compare the accuracy of reconstruction between VolSDF\(^{\dagger}\) and PointSLAM [Sandstro&umlm et al. 2023]. We report the mean \(L_1\) distances in cm (<u>lower is better</u>) across eight synthetic scenes from the Replica Dataset. For our experiments we use 15 temporally equidistant poses from 2000 RGBD images per scene in the dataset and train VolSDF\(^{\dagger}\) for 1500 iterations (\( \sim \) 21K gradient steps). For posed images, our errors on this simulated dataset closely reflect the performance of [Gropp et al. 2020] for approximating surfaces from noise-free, oriented point clouds. We report an average improvement of 81% over PointSLAM.

    </p>

    </div>
</div>
<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h5>
            <img src="./assets/reconstruction_benchmarks.png" alt="" class="img-responsive">
        </h5>
    </div>
</div> -->


<div class="row">
    <div class="col-md-6 col-md-offset-3">
        <h3>
            Collecting data with a manipulator versus a turn-table
        </h3>
        <h5>
            <p class="text-justify ">
            At its core, our method integrates a set of posed RGBD images to train a neural 3D model. As implemented, we assume the scene to be static and the rig moving. However, our pipeline can accommodate a turn-table. Note that commercial turn-table scanners integrate the data using a combination of the encoders on the turn-table and point cloud registration. The sytem's camera-projector pair is tuned to yield dense scene points at close distances. Our stereo backend has a limit on the disparity range and will break at those resolutions. The lowest camera-object distance we can accommodate is 400 mm with a 16 mm lens (see "Reconstructing a very shiny object" demo above), where we struggle due to the learnt stereo over-smoothing the disparities. To incorporate a turn-table to our pipeline, we remove visual features from the background and force our hybrid RGBD pose estimation system (sec 4.1) to focus on the foreground using depth based masking. The depth masks are not perfect, as a result, the pose estimates for data collected with a turn-table are worse than the case when the robot is moving. In the example below we take 6 RGBD images -- 3 stereo pairs in case for the moving camera, 6 RGBD captures (left channel of stereo) with the rotating turn-table. Train on 5 and test on 1 image, we use AdaShell\(^++\) for this demo. The quality of reconstruction suffers a bit for the case with turn-table, but more importantly, the current pose estimation pipeline breaks before the turn-table can rotate the object significantly. At the moment, this is an engineering problem which we believe is solvable by designing our own robot mounted camera-projector system, which is outside the scope of this work. 
        </p>
        </h5>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12  ">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="25%">
            <h4>Camera on robot (3 stereo pairs) </h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4> Ground Truth vs reconstruction  </h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Object on turntable (6 poses)  </h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4>Ground Truth vs reconstruction </h4>
        </td>
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome22" loop playsinline autoPlay muted src="assets/movies/flour_rgb_normal.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome22Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:90%">
                <video class="video" id="gnome23" loop playsinline autoPlay muted src="assets/movies/flour_bag.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome23Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome24" loop playsinline autoPlay muted src="assets/movies/turntable_rgb_normal.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome24Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:90%">
                <video class="video" id="gnome25" loop playsinline autoPlay muted src="assets/movies/turn_table.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome25Merge"></canvas>
            </div>
        </td>
    </tr>
</table>

<div class="container">
    <div class="row">
        <div class="col-md-12  ">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="25%">
            <h4>Turntable sequence </h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4> Multi-flash images  </h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4> Specular Tint </h4>
        </td>
        <td align="center" valign="center" width="25%">
            <h4> Relighting </h4>
        </td>
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:95%">
                <video class="video" id="gnome27" loop playsinline autoPlay muted src="assets/movies/shiny_L_R.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome27Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="video-compare-container" style="width:100%">
                <video class="video" id="gnome28" loop playsinline autoPlay muted src="assets/movies/shiny_L_R_all_data.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gnome28Merge"></canvas>
            </div>
        </td>
        <td align="center" valign="center" width="100%">
            <div class="sketchfab-embed-wrapper"> <iframe title="mesh" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; fullscreen; xr-spatial-tracking" xr-spatial-tracking execution-while-out-of-viewport execution-while-not-rendered web-share width="280" height="280" src="https://sketchfab.com/models/6698a4e268ab4c77a4e9d7a94347408a/embed"> </iframe> </div>
        </td>
        <td align="center" valign="center" width="100%">
            <video width="285" height="285" controls>
                <source src="assets/movies/turntable_shiny.mp4" type="video/mp4">
              </video>
        </td>   
    </tr>
</table>


</div>
</div>
</div>

<div class="row">
    <div class="col-md-12">
        <h3>
            View-point diversity or depth is required to train representations.
        </h3>
        <h5>
            <p class="text-justify ">
                In absence of depth, radiance based methods need viewpoint diversity to disambiguate between appearance and geometry. Additionally, monocular supervision is very dependent on the scene-network combination. We incorporate metric depth from stereo to capture appearance and geometry. Below we show our result on training on the ReNE reflective data sequence. ReLight My NeRF [Toschi et al. '23'] has a low view point diversity and does not supply metric depth. Our experiment below tries to train a radiance model (architechture v5 from Toschi et al.). With the given description and hyperparameters, our re-implementation of architechture v5 was unable to achieve the reported reconstruction quality. Additionally, monocular methods (as recommended by MonoSDF [Yu et al '22]) did not generate meaningful supervisions on this sequence. As a result, although we made some progress in view interpolation, the geometry recoverd in the process is meaningless.  
        </p>
        </h5>
    </div>
</div>

<div class="container">
    <div class="row">
        <div class="col-md-12">
<table width="100%">
    <tr>
        <td align="center" valign="center" width="33%">
            <h4>ReLightMyNeRF training images </h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4> Reconstructed radiance (PSNR 23.5)</h4>
        </td>
        <td align="center" valign="center" width="33%">
            <h4>Reconstructed shape</h4>
        </td>
        <!-- <td align="center" valign="center" width="25%">
            <h4>Normals and edges (Right)</h4>
        </td> -->
    </tr>
    <tr>
        <td align="center" valign="center" width="100%">
            <video width="370" height="281" controls>
                <source src="assets/movies/rene_train.mp4" type="video/mp4">
              </video>
        </td>
        <td align="right" valign="center" width="200%">
            <div class="img-comp-container">    
                <div class="img-comp-img">
                  <img src="./assets/rene_gt_big.png" width="259" height="197">
                </div>
                <div class="img-comp-img img-comp-overlay">
                  <img src="./assets/rene_reconst_big.png" width="259" height="197">
                </div>
        </div>
        </td>
        <td align="center" valign="center" width="100%">
            <video width="370" height="281" controls>
                <source src="assets/movies/ply_rene_cup.mp4" type="video/mp4">
              </video>
        </td>
    </tr>

</table> 
   

</div>
</div>
</div>




<!-- ----------------------------------- -->
<p class="br20"></p>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:0px">
            <br>
            <p style="text-align:center;font-size:small;">
            Part of the source code and design of this webpage is adapted from <a href="https://dorverbin.github.io/refnerf/"> Ref-NeRF project page</a>. We would like to thank the authors for the inspiration.
            </p>
        </td>
        </tr>
</tbody></table>
</div>


<script>
    /*Execute the Function*/
    compare();  
</script>



</body></html>


